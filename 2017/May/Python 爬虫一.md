从"0"开始写爬虫。

#####爬虫首先是个什么东西呢？
你可以理解成爬虫是一个小机器人，它可以批量的帮你访问网页，顺比记录数据。

#####那么从何做起呢？
Python 吧， Python 是一门高级语言，而且看起来跟英语很像，强制性的缩紧也可以帮助你养成良好的代码习惯。
推荐“廖雪峰”老师的Python 课程，当然流行了多年的《Learn Python the Hard Way.》也是不错的，而且还是免费注意，一定要去自己多写代码才好。我就是血泪教训。

#####你已经有了Python的基础
Python 的环境配置可以参考我的《Python 开发环境配置》。
我们详细的再来说说爬虫到底是什么。
作为人类，我们上网的时候通常步骤如下：
> 1. 打开浏览器
> 2. 然后输入需要进入的网址
> 3. 开始浏览网页，寻找自己需要的信息

以上的这些呢，都是人类的行为，爬虫可没有这么聪明。但是爬虫毕竟是人类开发的，那么很大程度上，其实是在模拟人类的行为。 那么，我们抽象一下上面的步骤再来看看。上面的关键点是什么。
> 1. 有效的网址。
> 2. 有效的信息。

上面我们讲到，爬虫是帮助你批量搜索信息的。那么我们就要明确，有效的信息是哪些咯。
比如说，我想要了解豆瓣上面的人都在读些什么“外国文学”。 那么打开“外国文学”这个标签，我们看到下面有很多的书籍，那么相关的书籍信息，就是我们需要抓取的信息了。我们看到一本书籍相关的信息包括： 作者、出版社、出版年、页数、定价、标题、评分等这些信息。但是似乎还是有点不太够呢？继续往下，我们看到有书评、短评、笔记以及想读、在读和读过的人数信息。嗯，这些字段应该差不多够了吧？

下面我们来普及一下网页相关的知识。我们知道一个网页是一个HTML、CSS、以及JavaScript 的结合。HTML是基础的网页内容。CSS呢，就是一个化妆师，JavaScript 负责教会网页怎么和人沟通。

Q:Scrapy是什么

A:Scrapy 是一个基于Python 的爬虫框架。就是帮你把许多的东西都做好了，你只需要告诉他需要访问什么页面，抓取什么信息就可以了。 我也没有写过爬虫框架，所以也仅限于这个程度的了解了。

Q:Selenium 是什么

A:也是一个爬虫框架，但是这货是基于浏览器的，可以更好的模拟人类行为，更加不容易被反爬虫机制所拦截。

Q:BeautifulSoup是什么

A:是一个帮助你从网页取得信息的库，帮助你解析HTML文件。或者说网站服务器回传的数据。 不过我们的教程中不会涉及到这个库的使用。